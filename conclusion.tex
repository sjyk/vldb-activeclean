\section{Conclusion}
The growing popularity of predictive models in data analytics adds additional challenges in managing dirty data.
We propose \sys, a model training framework that allows for iterative data cleaning while preserving provable convergence properties.
We specifically focus on problems that arise when data error is systematic, i.e., correlated with the hypotheses of interest.
The key insight of \sys is that convex loss models (e.g., linear regression and SVMs) can be simultaneously trained and cleaned.
%Consequently, there are provable guarantees on the convergence and error bounds of \sys.  
\sys also includes numerous optimizations such as: using the information from the model to inform data cleaning on samples, dirty data detection to avoid sampling clean data, and batching updates.
The experimental results are promising as they suggest that these optimizations can significantly reduce data cleaning costs when errors are sparse and cleaning budgets are small.
Techniques such as Active Learning and SampleClean are not optimized for the sparse low-budget setting, and \sys achieves models of high accuracy for significantly less records cleaned.